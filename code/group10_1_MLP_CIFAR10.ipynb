{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "group10_1-MLP-CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBeTObYWgx-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqxXM4CwvBU",
        "colab_type": "text"
      },
      "source": [
        "# Multi layer perceptron from scratch - CIFAR10 dataset\n",
        "\n",
        "**Reference:** https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
        "\n",
        "A neural network needs a few building blocks\n",
        "\n",
        "- Dense layer - a fully-connected layer, $f(X)=W \\cdot X + \\vec{b}$\n",
        "- ReLU layer (activation function to introduce non-linearity)\n",
        "- Loss function (crossentropy in case of multi-class classification problem)\n",
        "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
        "\n",
        "Let's approach them one at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KV9hnydxF61",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing some libraires required for creating our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpJbK3a4xNA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np ## For numerical python\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcCF8xGoxPxp",
        "colab_type": "text"
      },
      "source": [
        "Every layer will have a forward pass and backpass implementation. Let's create a main class layer which can do a forward pass .forward() and Backward pass .backward()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpzbNqK7xVu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "    \"\"\"\n",
        "    A building block. Each layer is capable of performing two things:\n",
        "\n",
        "    - Process input to get output:           output = layer.forward(input)\n",
        "    \n",
        "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
        "    \n",
        "    Some layers also have learnable parameters which they update during layer.backward.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Here we can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
        "        # A dummy layer does nothing\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
        "        \"\"\"\n",
        "        # A dummy layer just returns whatever it gets as input.\n",
        "        return input\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"\n",
        "        Performs a backpropagation step through the layer, with respect to the given input.\n",
        "        \n",
        "        To compute loss gradients w.r.t input, we need to apply chain rule (backprop):\n",
        "        \n",
        "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
        "        \n",
        "        Luckily, we already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
        "        \n",
        "        If our layer has parameters (e.g. dense layer), we also need to update them here using d loss / d layer\n",
        "        \"\"\"\n",
        "        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly\n",
        "        num_units = input.shape[1]\n",
        "        \n",
        "        d_layer_d_input = np.eye(num_units)\n",
        "        \n",
        "        return np.dot(grad_output, d_layer_d_input) # chain rule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxvFkKL8xYrf",
        "colab_type": "text"
      },
      "source": [
        "### Nonlinearity ReLU layer\n",
        "\n",
        "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8hw5XD5xcwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
        "        relu_forward = np.maximum(0,input)\n",
        "        return relu_forward\n",
        "    \n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
        "        relu_grad = input > 0\n",
        "        return grad_output*relu_grad "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMZDdM-wxksj",
        "colab_type": "text"
      },
      "source": [
        "### Dense layer\n",
        "\n",
        "Now let's build something more complicated. Unlike nonlinearity, a dense layer actually has something to learn.\n",
        "\n",
        "A dense layer applies affine transformation. In a vectorized form, it can be described as:\n",
        "$$f(X)= W \\cdot X + \\vec b $$\n",
        "\n",
        "Where \n",
        "* X is an object-feature matrix of shape [batch_size, num_features],\n",
        "* W is a weight matrix [num_features, num_outputs] \n",
        "* and b is a vector of num_outputs biases.\n",
        "\n",
        "Both W and b are initialized during layer creation and updated each time backward is called. Note that we are using **Xavier initialization** which is a trick to train our model to converge faster [read more](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization). Instead of initializing our weights with small numbers which are distributed randomly we initialize our weights with mean zero and variance of 2/(number of inputs + number of outputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YYfiVLTxrEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        A dense layer is a layer which performs a learned affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.normal(loc=0.0, \n",
        "                                        scale = np.sqrt(2/(input_units+output_units)), \n",
        "                                        size = (input_units,output_units))\n",
        "        self.biases = np.zeros(output_units)\n",
        "        \n",
        "    def forward(self,input):\n",
        "        \"\"\"\n",
        "        Perform an affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "        \n",
        "        input shape: [batch, input_units]\n",
        "        output shape: [batch, output units]\n",
        "        \"\"\"\n",
        "        return np.dot(input,self.weights) + self.biases\n",
        "    \n",
        "    def backward(self,input,grad_output):\n",
        "        # compute d f / d x = d f / d dense * d dense / d x\n",
        "        # where d dense/ d x = weights transposed\n",
        "        grad_input = np.dot(grad_output, self.weights.T)\n",
        "        \n",
        "        # compute gradient w.r.t. weights and biases\n",
        "        grad_weights = np.dot(input.T, grad_output)\n",
        "        grad_biases = grad_output.mean(axis=0)*input.shape[0]\n",
        "        \n",
        "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "        \n",
        "        # Here we perform a stochastic gradient descent step. \n",
        "        self.weights = self.weights - self.learning_rate * grad_weights\n",
        "        self.biases = self.biases - self.learning_rate * grad_biases\n",
        "        \n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn9GMtjAx19w",
        "colab_type": "text"
      },
      "source": [
        "### The loss function\n",
        "\n",
        "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
        "\n",
        "If we write down the expression for crossentropy as a function of softmax logits (a), you'll see:\n",
        "\n",
        "$$ loss = - log \\space {e^{a_{correct}} \\over {\\underset i \\sum e^{a_i} } } $$\n",
        "\n",
        "If we take a closer look, we'll see that it can be rewritten as:\n",
        "\n",
        "$$ loss = - a_{correct} + log {\\underset i \\sum e^{a_i} } $$\n",
        "\n",
        "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
        "* Better numerical stability\n",
        "* Easier to get derivative right\n",
        "* Marginally faster to compute\n",
        "\n",
        "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jd8GY5qyDHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
        "    \n",
        "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
        "    \n",
        "    return xentropy\n",
        "\n",
        "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    ones_for_answers = np.zeros_like(logits)\n",
        "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
        "    \n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "    \n",
        "    return (- ones_for_answers + softmax) / logits.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6DhLA6SyGFp",
        "colab_type": "text"
      },
      "source": [
        "### Full network\n",
        "\n",
        "Now let's combine what we've just built into a working neural network. We are going to use CIFAR10 data for our example. Fortunately, Keras already have it in the numpy array format, so let's import it!."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf6lodDvyJkE",
        "colab_type": "code",
        "outputId": "86065ef1-cbd9-4154-9787-9b958a440e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def load_dataset(flatten=False):\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=None)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                          download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "              'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    X_train = trainset.data\n",
        "    y_train = trainset.targets\n",
        "    X_test = testset.data\n",
        "    y_test = testset.targets\n",
        "\n",
        "    # normalize x\n",
        "    X_train = X_train.astype(float) / 255\n",
        "    X_test = X_test.astype(float) / 255\n",
        "\n",
        "    # we reserve the last 10000 training examples for validation\n",
        "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "\n",
        "    if flatten:\n",
        "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
        "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
        "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, classes, trainloader, testloader\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, classes, trainloader, testloader = load_dataset(flatten=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[0.23137255 0.24313725 0.24705882 ... 0.48235294 0.36078431 0.28235294]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhFuT5n6yszq",
        "colab_type": "text"
      },
      "source": [
        "We'll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ObqjlRNszHze",
        "colab": {}
      },
      "source": [
        "network = []\n",
        "network.append(Dense(X_train.shape[1],100))\n",
        "network.append(ReLU())\n",
        "network.append(Dense(100,200))\n",
        "network.append(ReLU())\n",
        "network.append(Dense(200,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-xiWos8yx-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(network, X):\n",
        "    \"\"\"\n",
        "    Compute activations of all network layers by applying them sequentially.\n",
        "    Return a list of activations for each layer. \n",
        "    \"\"\"\n",
        "    activations = []\n",
        "    input = X\n",
        "\n",
        "    # Looping through each layer\n",
        "    for l in network:\n",
        "        activations.append(l.forward(input))\n",
        "        # Updating input to last layer output\n",
        "        input = activations[-1]\n",
        "    \n",
        "    assert len(activations) == len(network)\n",
        "    return activations\n",
        "\n",
        "def predict(network,X):\n",
        "    \"\"\"\n",
        "    Compute network predictions. Returning indices of largest Logit probability\n",
        "    \"\"\"\n",
        "    logits = forward(network,X)[-1]\n",
        "    return logits.argmax(axis=-1)\n",
        "\n",
        "def train(network,X,y):\n",
        "    \"\"\"\n",
        "    Train our network on a given batch of X and y.\n",
        "    We first need to run forward to get all layer activations.\n",
        "    Then we can run layer.backward going from last to first layer.\n",
        "    After we have called backward for all layers, all Dense layers have already made one gradient step.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the layer activations\n",
        "    layer_activations = forward(network,X)\n",
        "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
        "    logits = layer_activations[-1]\n",
        "    \n",
        "    # Compute the loss and the initial gradient\n",
        "    loss = softmax_crossentropy_with_logits(logits,y)\n",
        "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
        "    \n",
        "    # Propagate gradients through the network\n",
        "    # Reverse propogation as this is backprop\n",
        "    for layer_index in range(len(network))[::-1]:\n",
        "        layer = network[layer_index]\n",
        "        \n",
        "        loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) #grad w.r.t. input, also weight updates\n",
        "        \n",
        "    return np.mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh2do8WOy2AE",
        "colab_type": "text"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "We split data into minibatches, feed each such minibatch into the network and update weights. This training method is called a mini-batch stochastic gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2dE8k6Fy3w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import trange\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert len(inputs) == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "firsEeFQSUnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_network(input_units, output_units, learning_rate=0.1, epochs=25, dense_output_units=[100, 200], print_network=False):\n",
        "    if print_network:\n",
        "        print('\\tNETWORK: Multi layer perceptron')\n",
        "    network = []\n",
        "    network.append(Dense(input_units, dense_output_units[0], learning_rate))\n",
        "    if print_network:\n",
        "        print('\\t\\tDense(input_units={}, output_units={}, learning_rate={})'.format(input_units, dense_output_units[0], learning_rate))\n",
        "    network.append(ReLU())\n",
        "    if print_network:\n",
        "        print('\\t\\tReLU()')\n",
        "    \n",
        "    for i, _ in enumerate(dense_output_units):\n",
        "      if i == len(dense_output_units) - 1:\n",
        "        break\n",
        "      network.append(Dense(dense_output_units[i], dense_output_units[i+1], learning_rate))\n",
        "      if print_network:\n",
        "          print('\\t\\tDense(input_units={}, output_units={}, learning_rate={})'.format(dense_output_units[i], dense_output_units[i+1], learning_rate))\n",
        "      network.append(ReLU())\n",
        "      if print_network:\n",
        "          print('\\t\\tReLU()')\n",
        "    \n",
        "    network.append(Dense(dense_output_units[-1], output_units))\n",
        "    if print_network:\n",
        "        print('\\t\\tDense(input_units={}, output_units={}, learning_rate={})'.format(dense_output_units[-1], output_units, learning_rate))\n",
        "\n",
        "    return network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4nPt8_qEr8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import time\n",
        "\n",
        "def training_loop(network, input_units, output_units, learning_rate=0.1, epochs=25, dense_output_units=[100, 200], batchsize=32, shuffle=True):\n",
        "    if len(dense_output_units) < 2:\n",
        "      return\n",
        "\n",
        "    epoch_start = time()\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    epoch_time_list = []\n",
        "\n",
        "    last_train_accuracy = 0.0\n",
        "    last_validation_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=batchsize,shuffle=shuffle):\n",
        "            train(network,x_batch,y_batch)\n",
        "        \n",
        "        train_acc_list.append(np.mean(predict(network,X_train)==y_train))\n",
        "        val_acc_list.append(np.mean(predict(network,X_val)==y_val))\n",
        "        \n",
        "        clear_output()\n",
        "        print(\"Epoch\", epoch)\n",
        "        print(\"Training accuracy: {:.2f}%\".format(train_acc_list[-1]*100))\n",
        "        print(\"Validation accuracy: {:.2f}%\".format(val_acc_list[-1]*100))\n",
        "        epoch_time = time() - epoch_start\n",
        "        epoch_time_list.append(epoch_time)\n",
        "        print(\"Epoch's processing time: {:.2f} seconds\".format(epoch_time))\n",
        "        plt.plot(train_acc_list, label='train accuracy')\n",
        "        plt.plot(val_acc_list, label='val accuracy')\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "    \n",
        "    return train_acc_list, val_acc_list, epoch_time_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oxbBgkZgy3Q",
        "colab_type": "text"
      },
      "source": [
        "## Testing different dense layers\n",
        "\n",
        "* Using 2 dense layers with learning_rate=0.1 (100 and 200 output units). Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate=0.1 (100, 200, and 300 output units). Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 4 dense layers with learning_rate=0.1 (100, 200, 300 and 400 output units). Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 5 dense layers with learning_rate=0.1 (100, 200, 300, 400, and 500 output units). Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEn36rvQtEF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_accuracy_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MeSEs45EhKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "\n",
        "def mlp_training(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle):\n",
        "    training_start = time()\n",
        "    train_acc_list, val_acc_list, epoch_time_list = training_loop(network, input_units=input_units, output_units=output_units, learning_rate=learning_rate, epochs=epochs, dense_output_units=dense_output_units, batchsize=batchsize, shuffle=shuffle)\n",
        "    print(\"Total time: {} seconds\".format(time() - training_start))\n",
        "\n",
        "    labels = ['epoch {}'.format(str(i).zfill(3)) for i in range(epochs)]\n",
        "\n",
        "    train_acc_np = np.asarray(train_acc_list)\n",
        "    print(\"\\nTraining accuracy list: {}\".format(train_acc_np))\n",
        "    print(\"Training accuracy (Mean +/- Std): %0.2f (+/- %0.2f)\" % (train_acc_np.mean()*100, train_acc_np.std() * 2))\n",
        "    # Plot horizontal bar\n",
        "    values = [v * 100 for v in train_acc_list]\n",
        "    plot_horizontal_bar(labels, values, xlabel='Accuracy', ylabel='', title='Training accuracy per epoch', use_xlim=True)\n",
        "\n",
        "    val_acc_np = np.asarray(val_acc_list)\n",
        "    print(\"\\nValidation accuracy list: {}\".format(val_acc_np))\n",
        "    print(\"Validation accuracy (Mean +/- Std): %0.2f (+/- %0.2f)\" % (val_acc_np.mean()*100, val_acc_np.std() * 2))\n",
        "\n",
        "    # Save validation accuracy to plotting: Validation accuracy Vs Number of dense layers\n",
        "    validation_accuracy_list.append(val_acc_np.mean()*100)\n",
        "\n",
        "    # Plot horizontal bar\n",
        "    values = [v * 100 for v in val_acc_list]\n",
        "    plot_horizontal_bar(labels, values, xlabel='Accuracy', ylabel='', title='Validation accuracy per epoch', use_xlim=True)\n",
        "\n",
        "    epoch_time_np = np.asarray(epoch_time_list)\n",
        "    print(\"\\nEpoch time list: {}\".format(epoch_time_np))\n",
        "    print(\"Epoch time (Mean +/- Std): %0.2f (+/- %0.2f)\" % (epoch_time_np.mean(), epoch_time_np.std() * 2))\n",
        "    # Plot horizontal bar\n",
        "    values = [v * 100 for v in epoch_time_list]\n",
        "    plot_horizontal_bar(labels, values, xlabel='Time', ylabel='', title='Epoch time in seconds', use_xlim=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsV7BWGTIGoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_horizontal_bar(x, y, xlabel, ylabel, title, use_xlim=False):\n",
        "    fig, ax = plt.subplots()    \n",
        "    width = 0.75 # the width of the bars \n",
        "    ind = np.arange(len(y))  # the x locations for the groups\n",
        "    ax.barh(ind, y, width, color=\"blue\")\n",
        "    ax.set_yticks(ind+width/2)\n",
        "    ax.set_yticklabels(x, minor=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)      \n",
        "\n",
        "    for i, v in enumerate(y):\n",
        "        ax.text(v + 3, i + .25, '%0.2f'%(v), color='blue', fontweight='bold')\n",
        "    \n",
        "    if use_xlim:\n",
        "        plt.xlim(0, 120)\n",
        "        plt.tight_layout()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPWaU7GJsHkh",
        "colab_type": "text"
      },
      "source": [
        "### Using **2 dense layers** (100 and 200 output units) with learning_rate=0.1 . Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GroEYzq5ItHc",
        "colab_type": "code",
        "outputId": "2641712d-6738-4a7c-edb8-1eff30c719d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dense_output_units=[100, 200]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tNETWORK: Multi layer perceptron\n",
            "\t\tDense(input_units=3072, output_units=100, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=100, output_units=200, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=200, output_units=10, learning_rate=0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpvEkYSwUqwU",
        "colab_type": "code",
        "outputId": "8df06059-561a-485d-8c85-c2b91bfd43d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# TODO FIX BUG\n",
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.1, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6112eb8b39fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4KXj7dJd3mb",
        "colab_type": "text"
      },
      "source": [
        "### Using **3 dense layers** (100, 200 and 300 output units) with learning_rate=0.1 . Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR3_eKpaM2B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_output_units=[100, 200, 300]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYUfyy8FVkJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0fbe64d8-ec06-4a6f-dbe3-ba2b56485138"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.1, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6112eb8b39fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upaWPO1_gJpa",
        "colab_type": "text"
      },
      "source": [
        "### Using **4 dense layers** (100, 200, 300 and 400 output units) with learning_rate=0.1 . Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBnM1bAWe2Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_output_units=[100, 200, 300, 400]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HASO3RAIe6T6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b7e7820f-f213-482c-c734-859c9320b94a"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.1, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6112eb8b39fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trsuHNbAgVZs",
        "colab_type": "text"
      },
      "source": [
        "### Using **5 dense layers** (100, 200, 300, 400 and 500 output units) with learning_rate=0.1 . Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzJN8HVe8wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_output_units=[100, 200, 300, 400, 500]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kBkKJYpfALU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.1, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRmEjp1arBRz",
        "colab_type": "text"
      },
      "source": [
        "## Best number of dense layers\n",
        "\n",
        "* Highest validation accuracy (mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MowijbJsaaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f6285a1f-f0d4-4ce0-b55d-b95521c28dcd"
      },
      "source": [
        "labels = ['2 dense layers', '3 dense layers', '4 dense layers', '5 dense layers']\n",
        "plot_horizontal_bar(labels, validation_accuracy_list, xlabel='Validation accuracy', ylabel='', title='Validation accuracy Vs Number of dense layers', use_xlim=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f9455c56b59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2 dense layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3 dense layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4 dense layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'5 dense layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_horizontal_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation accuracy Vs Number of dense layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-d205da539b63>\u001b[0m in \u001b[0;36mplot_horizontal_bar\u001b[0;34m(x, y, xlabel, ylabel, title, use_xlim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_horizontal_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m \u001b[0;31m# the width of the bars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the x locations for the groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sW4WQuN20O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_accuracy_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHp2ut-G0zb1",
        "colab_type": "text"
      },
      "source": [
        "## Testing different learning rates\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.1. Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.01. Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.0001. Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk55gF7w02bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "13ac08d4-f646-4a9e-c68c-bacc356f14b9"
      },
      "source": [
        "dense_output_units=[100, 200, 300]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tNETWORK: Multi layer perceptron\n",
            "\t\tDense(input_units=3072, output_units=100, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=100, output_units=200, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=200, output_units=300, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=300, output_units=10, learning_rate=0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi-sUdNe1Rdy",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with **learning_rate = 0.1**. Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qXFJk3055h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "52a523d5-34ab-4f57-bed9-65f3c2a891b8"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.1, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6112eb8b39fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doE5h6Lg1Vu3",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with **learning_rate = 0.01**. Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbCUx0rm1aYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8c5cea87-64b9-483c-9355-0b88cf2200d1"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.01, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-464fe393e384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS1ZAB_W1maL",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with **learning_rate = 0.001**. Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pOKoEYB1nHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSD88nXP1ncp",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with **learning_rate = 0.0001**. Minibatches: batchsize=32, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt1O1EBy1nrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.0001, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjF6BM_e6McS",
        "colab_type": "text"
      },
      "source": [
        "## Best learning rate\n",
        "\n",
        "* Highest validation accuracy (mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s626l3qn6SfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "1fa539a0-bcf8-4893-be1c-f72af1644637"
      },
      "source": [
        "labels = ['lr=0.1', 'lr=0.01', 'lr=0.001', 'lr=0.0001']\n",
        "plot_horizontal_bar(labels, validation_accuracy_list, xlabel='Validation accuracy', ylabel='', title='Validation accuracy Vs Learning rate', use_xlim=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-db4ebf6ae3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lr=0.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr=0.01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr=0.001'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr=0.0001'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_horizontal_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation accuracy Vs Learning rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-d205da539b63>\u001b[0m in \u001b[0;36mplot_horizontal_bar\u001b[0;34m(x, y, xlabel, ylabel, title, use_xlim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_horizontal_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m \u001b[0;31m# the width of the bars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the x locations for the groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fzDF_x39EF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_accuracy_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faA3SBiv83Yw",
        "colab_type": "text"
      },
      "source": [
        "## Testing different batch size\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=8, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=16, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=32, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=64, shuffle=True\n",
        "\n",
        "* Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=128, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7s13lK69WIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_output_units=[100, 200, 300]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OYZK1H59bbR",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: **batchsize=8**, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thNRem789aqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw4yGzag9tE9",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: **batchsize=16**, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jywRrQov9tVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "853717e0-3fc8-45e2-c892-bba71077b63f"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=16, shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2500 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b38e3e9470f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YOh0uhC9tw7",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: **batchsize=32**, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpthQPzA9uBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvEZvY9h9uSf",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: **batchsize=64**, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDzjr9mP9uer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD2Zw0TQ9uqr",
        "colab_type": "text"
      },
      "source": [
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: **batchsize=128**, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVEIeKpd9u1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=128, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Dpogm5-RtW",
        "colab_type": "text"
      },
      "source": [
        "## Best batch size\n",
        "\n",
        "* Highest validation accuracy (mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP-vUNrW-W8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['batchsize=8', 'batchsize=16', 'batchsize=32', 'batchsize=64', 'batchsize=128']\n",
        "plot_horizontal_bar(labels, validation_accuracy_list, xlabel='Validation accuracy', ylabel='', title='Validation accuracy Vs Batch size', use_xlim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNWTuhutCLZb",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion: Best MLP model\n",
        "\n",
        "### Using 3 dense layers with learning_rate = 0.001. Minibatches: batchsize=64, shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJLJNYAZCf3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5afa9b31-ee81-4b2b-baad-bd4df6b94fd1"
      },
      "source": [
        "dense_output_units=[100, 200, 300]\n",
        "\n",
        "network = get_network(input_units=X_train.shape[1], output_units=10, epochs=25, dense_output_units=dense_output_units, print_network=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tNETWORK: Multi layer perceptron\n",
            "\t\tDense(input_units=3072, output_units=100, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=100, output_units=200, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=200, output_units=300, learning_rate=0.1)\n",
            "\t\tReLU()\n",
            "\t\tDense(input_units=300, output_units=10, learning_rate=0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_IVXH9gCnLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "80cf9996-fd29-4178-9095-85dace1ba039"
      },
      "source": [
        "mlp_training(network, input_units=X_train.shape[1], output_units=10, learning_rate=0.001, epochs=25, dense_output_units=dense_output_units, batchsize=64, shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/625 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e6800a0bdee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-322cd63d9a28>\u001b[0m in \u001b[0;36mmlp_training\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time: {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ec7bd5449bca>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(network, input_units, output_units, learning_rate, epochs, dense_output_units, batchsize, shuffle)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e87c32f38ed>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(inputs, targets, batchsize, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mexcerpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    }
  ]
}